#!/bin/bash

# --- Configuration ---
MODEL_NAME="shk-turbo-mini"
VOCAB_SIZE=30522
HIDDEN_SIZE=512
NUM_LAYERS=6
NUM_HEADS=8
BATCH_SIZE=32
SEQ_LEN=512
DROPOUT=0.1
ACTIVATION_FUNCTION="gelu"

# --- Reproducibility ---
SEED=42

# --- Base Training ---
TRAIN_DATA="data/train.txt"
VALID_DATA="data/valid.txt"
LEARNING_RATE=1e-4
WARMUP_STEPS=1000
TRAIN_STEPS=10000
GRADIENT_ACCUMULATION_STEPS=4
CHECKPOINT_INTERVAL=1000
LOG_DIR_TRAIN="logs/train"

# --- Fine-Tuning ---
FT_TRAIN_DATA="data/vobr_train.txt"
FT_VALID_DATA="data/vobr_valid.txt"
FT_LEARNING_RATE=5e-5
FT_TRAIN_STEPS=5000
FT_CHECKPOINT_INTERVAL=500
LOG_DIR_FT="logs/fine_tune"
FREEZE_LAYERS=true

# --- Create dummy data files ---
mkdir -p data
echo "This is a dummy training sentence." > $TRAIN_DATA
echo "This is a dummy validation sentence." > $VALID_DATA
echo "This is a dummy fine-tuning training sentence." > $FT_TRAIN_DATA
echo "This is a dummy fine-tuning validation sentence." > $FT_VALID_DATA

# --- Script ---

# Create model directory
mkdir -p $MODEL_NAME

# Create model configuration file
cat > $MODEL_NAME/config.json <
{
  "vocab_size": $VOCAB_SIZE,
  "hidden_size": $HIDDEN_SIZE,
  "num_layers": $NUM_LAYERS,
  "num_heads": $NUM_HEADS,
  "batch_size": $BATCH_SIZE,
  "seq_len": $SEQ_LEN,
  "dropout": $DROPOUT,
  "activation_function": "$ACTIVATION_FUNCTION"
}
EOF

# Train the model
echo "--- Starting Base Training ---"
python train.py \
  --model_name $MODEL_NAME \
  --train_data $TRAIN_DATA \
  --valid_data $VALID_DATA \
  --learning_rate $LEARNING_RATE \
  --warmup_steps $WARMUP_STEPS \
  --train_steps $TRAIN_STEPS \
  --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \
  --seed $SEED \
  --checkpoint_interval $CHECKPOINT_INTERVAL \
  --log_dir $LOG_DIR_TRAIN

# Get the last checkpoint from base training
LAST_CHECKPOINT=$(ls -t $MODEL_NAME/checkpoints/step_*.pt 2>/dev/null | head -1)

if [ -z "$LAST_CHECKPOINT" ]; then
  echo "Error: No checkpoint found in $MODEL_NAME/checkpoints/. Exiting."
  exit 1
fi

echo "Found latest checkpoint: $LAST_CHECKPOINT"

# Fine-tune the model
echo "--- Starting Fine-Tuning ---"
python fine_tune.py \
  --model_name $MODEL_NAME \
  --train_data $FT_TRAIN_DATA \
  --valid_data $FT_VALID_DATA \
  --learning_rate $FT_LEARNING_RATE \
  --train_steps $FT_TRAIN_STEPS \
  --gradient_accumulation_steps $GRADIENT_ACCUMULATION_STEPS \
  --seed $SEED \
  --checkpoint_interval $FT_CHECKPOINT_INTERVAL \
  --log_dir $LOG_DIR_FT \
  --checkpoint_path $LAST_CHECKPOINT \
  $([ "$FREEZE_LAYERS" = true ] && echo "--freeze_layers")
